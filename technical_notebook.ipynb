{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Housing Stock\n",
    "Classifying Adequate Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. <a href ='#goal'>Problem Statement</a>\n",
    "2. <a href='#terms'>Key Terminology</a>\n",
    "3. <a href='#datasources'>Data Sources</a>\n",
    "4. <a href='#EDA'>Exploratory Data Analysis</a>\n",
    "5. <a href='#models'>Classification</a>\n",
    " 1. <a href='#model1'>Logistic Regression</a> \n",
    " 2. <a href='#model2'>Random Forest</a>\n",
    " 3. <a href='#model3'>SVM</a>\n",
    "6. <a href='#findings'>Recommendations</a>\n",
    "7. <a href='#recs'>Next Steps</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seohohahm/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and set defaults\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.style.palettes import PALETTES, SEQUENCES, color_palette\n",
    "color_palette(palette='flatui', n_colors=8)\n",
    "from yellowbrick.style import set_palette\n",
    "set_palette('pastel')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal'></a>\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis aims to assist the U.S. Department of Housing & Urban Development (HUD) to better understand housing stock.  To evaluate this topic, HUD aims to address the following questions: \n",
    "\n",
    "1.  What features are important for classifying units as adequate?\n",
    "2.  Are these the same features that determine whether a unit is classified as vacant?  What about classifying whether a unit is affordable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='terms'></a>\n",
    "## Key Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **U.S. Department of Housing & Urban Development (HUD)**:  federal agency dedicated to strengthening and supporting the housing market; primary responsibilities include:\n",
    "  -  Protecting housing consumers\n",
    "  -  Encouraging production of affordable rental housing\n",
    "  -  Preventing and punishing discrimination in housing\n",
    "- **Housing stock**:  total number of houses, apartments, or other dwellings\n",
    "- **Housing unit**:  a single house, apartment, or other dwelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasources'></a>\n",
    "## Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### American Housing Survey (AHS)\n",
    "(https://www.census.gov/programs-surveys/ahs.html)\n",
    "\n",
    "-  Biennial voluntary longitudinal survey that provides current and ongoing series of data on the size, composition, and state of housing in the United States and changes in the housing stock over time\n",
    "-  Collects housing statistics that the U.S. Department of Housing and Urban Development (HUD) uses to evaluate and develop its federal housing programs\n",
    "-  Sample size dependent on HUD budget and has varied over the years (e.g. in 2009 about 62,000 addresses were selected for the National survey)\n",
    "-  Each sample unit from the basic sample has been visited every other year since 1985. New addresses are added to the sample at each iteration to ensure representativeness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "clean_df = pd.read_csv('data/ahs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='EDA'></a>\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy model\n",
    "X = clean_df.drop(['ADEQUACY_BIN'], axis=1)\n",
    "y = clean_df.ADEQUACY_BIN\n",
    "\n",
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_labels = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always predicts the most frequent label in the training set\n",
    "dummy0 = DummyClassifier(strategy='most_frequent')\n",
    "dummy0.fit(X_train_0, y_train_0)\n",
    "dummy0.score(X_test_0, y_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(dummy0, cmap='RdBu');\n",
    "cm.score(X_test_0, y_test_0);\n",
    "cm.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({1: 62185, 0: 62185})\n"
     ]
    }
   ],
   "source": [
    "# Balancing classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model1'></a>\n",
    "### 1)  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', RandomForestClassifier(max_depth=30, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80     12437\n",
      "           1       0.80      0.80      0.80     12437\n",
      "\n",
      "    accuracy                           0.80     24874\n",
      "   macro avg       0.80      0.80      0.80     24874\n",
      "weighted avg       0.80      0.80      0.80     24874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up grid search\n",
    "param_grid = dict(clf__n_estimators = [80,100,120],\n",
    "                  clf__max_depth = [25,30,35,40],\n",
    "                  clf__min_samples_split = [5, 20, 100],\n",
    "                  clf__min_samples_leaf = [1, 2, 5, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = {}\n",
    "for feature, importance in zip(X_labels, pipe[1].feature_importances_):\n",
    "    feats[feature] = importance\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "importances.sort_values(by='importance', inplace=True, ascending=False)\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(grid_search, cmap='RdBu');\n",
    "cm.score(X_test, y_test);\n",
    "cm.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model2'></a>\n",
    "### 2)  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[1] = LogisticRegression(random_state=42)\n",
    "\n",
    "param_grid = dict(scaler=['passthrough'],\n",
    "                  clf__penalty=['l1', None],\n",
    "                  clf__C=[.001, 0.01, .1, 1, 10])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(grid_search, cmap='RdBu');\n",
    "cm.score(X_test, y_test);\n",
    "cm.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model3'></a>\n",
    "### 3)  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[1] = SVC(random_state=42)\n",
    "\n",
    "param_grid = dict(clf__C = [0.1, 10, 100],\n",
    "                  clf__gamma = [1, 0.01, 0.0001],\n",
    "                  clf__kernel = ['rbf', 'polynomial'])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(grid_search, cmap='RdBu');\n",
    "cm.score(X_test, y_test);\n",
    "cm.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='findings'></a>\n",
    "## Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal clinic can address issues related to D.C. housing by:\n",
    "1.  Taking into account the disproportionate impact of evictions on D.C.â€™s non-white population by setting up clinics in historically black communities\n",
    "2.  Advocate that PUDs follow through on community benefits such as the provision of affordable housing or charitable contribution to local nonprofit focused on equitable development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='recs'></a>\n",
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Continue analysis at block group level, accounting for the fact that a PUD may be adjacent to one or more block groups\n",
    "2. Repeat analysis, taking into account PUD status as of 2016 (year of eviction rate data)\n",
    "3. Evaluate findings across time series data, including development timeline of PUD\n",
    "4. Repeat analysis with other development vehicles, such as Tax Increment Financing\n",
    "5. Synthesize findings with additional research about PUD community impact beyond count of affordable units, such as count of family-sized units, project value, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
